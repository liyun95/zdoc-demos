{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering Using Zilliz Cloud and Cohere\n",
    "\n",
    "This page illustrates how to create a question-answering system based on the SQuAD dataset using Zilliz Cloud as the vector database and Cohere as the embedding system.\n",
    "\n",
    "## Before you start\n",
    "\n",
    "Code snippets on this page require pymilvus, cohere, pandas, numpy, and tqdm installed. Among these packages, pymilvus is the client for Zilliz Cloud. If these packages are not present on your system, run the following commands to install them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymilvus in /Users/zilliz/miniforge3/lib/python3.10/site-packages (2.3.2)\n",
      "Requirement already satisfied: cohere in /Users/zilliz/miniforge3/lib/python3.10/site-packages (4.32)\n",
      "Requirement already satisfied: pandas in /Users/zilliz/miniforge3/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: numpy in /Users/zilliz/miniforge3/lib/python3.10/site-packages (1.25.0)\n",
      "Requirement already satisfied: tqdm in /Users/zilliz/miniforge3/lib/python3.10/site-packages (4.66.1)\n",
      "Requirement already satisfied: grpcio<=1.58.0,>=1.49.1 in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from pymilvus) (1.58.0)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from pymilvus) (4.25.0)\n",
      "Requirement already satisfied: environs<=9.5.0 in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from pymilvus) (9.5.0)\n",
      "Requirement already satisfied: ujson>=2.0.0 in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from pymilvus) (5.8.0)\n",
      "Requirement already satisfied: requests in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from pymilvus) (2.31.0)\n",
      "Requirement already satisfied: minio>=7.0.0 in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from pymilvus) (7.1.17)\n",
      "Requirement already satisfied: aiohttp<4.0,>=3.0 in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from cohere) (3.8.5)\n",
      "Requirement already satisfied: backoff<3.0,>=2.0 in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from cohere) (2.2.1)\n",
      "Requirement already satisfied: fastavro==1.8.2 in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from cohere) (1.8.2)\n",
      "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from cohere) (6.8.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from cohere) (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0,>=3.0->cohere) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0,>=3.0->cohere) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
      "Requirement already satisfied: marshmallow>=3.0.0 in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from environs<=9.5.0->pymilvus) (3.20.1)\n",
      "Requirement already satisfied: python-dotenv in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from environs<=9.5.0->pymilvus) (1.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.16.2)\n",
      "Requirement already satisfied: certifi in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from minio>=7.0.0->pymilvus) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.5 in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from requests->pymilvus) (3.4)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/zilliz/miniforge3/lib/python3.10/site-packages (from marshmallow>=3.0.0->environs<=9.5.0->pymilvus) (23.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymilvus cohere pandas numpy tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you need to load the modules to be used in this guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PyMilvus in development\n",
    "# Should be replaced with `from pymilvus import *` in production\n",
    "# from pathlib import Path\n",
    "# import sys\n",
    "# sys.path.append(str(Path(\"/Users/anthony/Documents/play/refine_milvus/pymilvus\")))\n",
    "\n",
    "from pymilvus import connections, DataType, CollectionSchema, FieldSchema, Collection, utility\n",
    "import cohere\n",
    "import pandas\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "Here we can find the parameters used in the following snippets. Some of them need to be changed to fit your environment. Beside each is a description of what it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up arguments\n",
    "\n",
    "# 1. Set the The SQuAD dataset url.\n",
    "FILE = 'https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json' \n",
    "\n",
    "# 2. Set up the name of the collection to be created.\n",
    "COLLECTION_NAME = 'question_answering_db'\n",
    "\n",
    "# 3. Set up the dimension of the embeddings.\n",
    "DIMENSION = 768\n",
    "\n",
    "# 4. Set the number of entities to create and the number of entities to insert at a time.\n",
    "COUNT = 5000\n",
    "BATCH_SIZE = 96\n",
    "\n",
    "# 5. Set up the cohere api key\n",
    "COHERE_API_KEY = \"YOUR_COHERE_API_KEY\"\n",
    "\n",
    "# 6. Set up the connection parameters for your Zilliz Cloud cluster.\n",
    "URI = 'YOUR_CLUSTER_ENDPOINT'\n",
    "TOKEN = 'YOUR_CLUSTER_TOKEN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To know more about the model and dataset used on this page, refer to [Cohere](https://cohere.ai/) and [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/).\n",
    "\n",
    "## Prepare dataset\n",
    "\n",
    "In this example, we are going to use the Stanford Question Answering Dataset (SQuAD) as our truth source for answering questions. This dataset comes in the form of a JSON file and we are going to use pandas to load it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "dataset = pandas.read_json(FILE)\n",
    "\n",
    "# Clean up the dataset by grabbing all the question answer pairs\n",
    "simplified_records = []\n",
    "for x in dataset['data']:\n",
    "    for y in x['paragraphs']:\n",
    "        for z in y['qas']:\n",
    "            if len(z['answers']) != 0:\n",
    "                simplified_records.append({'question': z['question'], 'answer': z['answers'][0]['text']})\n",
    "\n",
    "# Grab the amount of records based on COUNT\n",
    "simplified_records = pandas.DataFrame.from_records(simplified_records)\n",
    "simplified_records = simplified_records.sample(n=min(COUNT, len(simplified_records)), random_state = 42)\n",
    "\n",
    "# Check if the length of the cleaned dataset matches COUNT\n",
    "print(len(simplified_records))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a collection\n",
    "\n",
    "This section deals with Zilliz Cloud and setting up the cluster for this use case. Within Zilliz Cloud, we need to set up a collection and index it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status(code=0, message=)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to Zilliz Cloud and create a collection\n",
    "\n",
    "connections.connect(\n",
    "    alias='default',\n",
    "    # Public endpoint obtained from Zilliz Cloud\n",
    "    uri=URI,\n",
    "    token=TOKEN\n",
    ")\n",
    "\n",
    "if COLLECTION_NAME in utility.list_collections():\n",
    "    utility.drop_collection(COLLECTION_NAME)\n",
    "\n",
    "fields = [\n",
    "    FieldSchema(name='id', dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "    FieldSchema(name='original_question', dtype=DataType.VARCHAR, max_length=1000),\n",
    "    FieldSchema(name='answer', dtype=DataType.VARCHAR, max_length=1000),\n",
    "    FieldSchema(name='original_question_embedding', dtype=DataType.FLOAT_VECTOR, dim=DIMENSION)\n",
    "]\n",
    "\n",
    "schema = CollectionSchema(fields=fields)\n",
    "\n",
    "collection = Collection(\n",
    "    name=COLLECTION_NAME,\n",
    "    schema=schema,\n",
    ")\n",
    "\n",
    "index_params = {\n",
    "    'metric_type': 'L2',\n",
    "    'index_type': 'AUTOINDEX',\n",
    "    'params': {'nlist': 1024}\n",
    "}\n",
    "\n",
    "collection.create_index(\n",
    "    field_name='original_question_embedding', \n",
    "    index_params=index_params\n",
    ")\n",
    "\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert data\n",
    "\n",
    "Once we have the collection set up, we need to start inserting our data. This is done in three steps:\n",
    "\n",
    "- reading the data,\n",
    "\n",
    "- embedding the original questions, and\n",
    "\n",
    "- inserting the data into the collection we've just created on Zilliz Cloud.\n",
    "\n",
    "In this example, the data includes the original question, the original question's embedding, and the answer to the original question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [02:53<00:00,  3.27s/it]\n"
     ]
    }
   ],
   "source": [
    "# Set up a Cohere client\n",
    "cohere_client = cohere.Client(COHERE_API_KEY)\n",
    "\n",
    "# Extract embeddings from questions using Cohere\n",
    "def embed(texts):\n",
    "    res = cohere_client.embed(texts, model='multilingual-22-12')\n",
    "    return res.embeddings\n",
    "\n",
    "# Insert each question, answer, and qustion embedding\n",
    "total = pandas.DataFrame()\n",
    "for batch in tqdm(np.array_split(simplified_records, (COUNT/BATCH_SIZE) + 1)):\n",
    "    questions = batch['question'].tolist()\n",
    "    embeddings = embed(questions)\n",
    "    \n",
    "    data = [\n",
    "        {\n",
    "            'original_question': x,\n",
    "            'answer': batch['answer'].tolist()[i],\n",
    "            'original_question_embedding': embeddings[i]\n",
    "        } for i, x in enumerate(questions)\n",
    "    ]\n",
    "\n",
    "    collection.insert(data=data)\n",
    "\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask questions\n",
    "\n",
    "Once all the data is inserted into the Zilliz Cloud collection, we can ask the system questions by taking our question phrase, embedding it with Cohere, and searching with Zilliz Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search the cluster for an answer to a question text\n",
    "def search(text, top_k = 5):\n",
    "\n",
    "    # AUTOINDEX does not require any search params \n",
    "    search_params = {}\n",
    "\n",
    "    results = collection.search(\n",
    "        data = embed([text]),  # Embeded the question\n",
    "        anns_field='original_question_embedding',\n",
    "        param=search_params,\n",
    "        limit = top_k,  # Limit to top_k results per search\n",
    "        output_fields=['original_question', 'answer']  # Include the original question and answer in the result\n",
    "    )\n",
    "\n",
    "    # ret = []\n",
    "    # for hit in results[0]:\n",
    "    #     row = []\n",
    "    #     row.extend([hit['entity']['answer'], hit['distance'], hit['entity']['original_question'] ])  # Get the answer, distance, and original question for the results\n",
    "    #     ret.append(row)\n",
    "    # return ret\n",
    "\n",
    "    distances = results[0].distances\n",
    "    entities = [ x.entity.to_dict()['entity'] for x in results[0] ]\n",
    "\n",
    "    ret = [ {\n",
    "        \"answer\": x[1][\"answer\"],\n",
    "        \"distance\": x[0],\n",
    "        \"original_question\": x[1]['original_question']\n",
    "    } for x in zip(distances, entities)]\n",
    "\n",
    "    return ret\n",
    "\n",
    "# Ask these questions\n",
    "search_questions = ['What kills bacteria?', 'What\\'s the biggest dog?']\n",
    "\n",
    "# Print out the results in order of [answer, similarity score, original question]\n",
    "\n",
    "ret = [ { \"question\": x, \"candidates\": search(x) } for x in search_questions ]\n",
    "\n",
    "print(ret)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
