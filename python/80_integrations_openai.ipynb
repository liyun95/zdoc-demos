{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai pymilvus>=2.3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Search with Zilliz Cloud and OpenAI\n",
    "\n",
    "This page discusses integrating vector databases with OpenAI's embedding API.\n",
    "\n",
    "We will demonstrate how to use OpenAI's [Embedding API](https://beta.openai.com/docs/guides/embeddings) with our vector database to search for book titles. Many existing book search solutions, such as those used by public libraries, rely on keyword matching rather than a semantic understanding of the title's meaning. Using a trained model to represent the input data is known as semantic search and can be applied to a variety of different text-based use cases, including anomaly detection and document search.\n",
    "\n",
    "## Get started\n",
    "\n",
    "To follow along, you'll need an API key from the [OpenAI website](https://openai.com/api/). Also, be sure to visit our [cloud landing page](https://zilliz.com/cloud) for free credits that you can use to spin up a new cluster if you donâ€™t have one already.\n",
    "\n",
    "We'll also need to prepare the data for this example. You can obtain the book titles from [here](https://www.kaggle.com/datasets/jealousleopard/goodreadsbooks). Let's create a function that loads book titles from our CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PyMilvus in development\n",
    "# Should be replaced with `from pymilvus import *` in production\n",
    "# from pathlib import Path\n",
    "# import sys\n",
    "# sys.path.append(str(Path(\"/Users/anthony/Documents/play/refine_milvus/pymilvus\")))\n",
    "\n",
    "import csv, random, time\n",
    "import openai\n",
    "from pymilvus import connections, DataType, CollectionSchema, FieldSchema, Collection, utility\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare arguments\n",
    "\n",
    "In this section, we need to set up an environment for us to embed the extracted titles, insert the embeddings into a Zilliz Cloud collection, and conduct an ANN search against them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up arguments\n",
    "\n",
    "# 1. Go to https://www.kaggle.com/datasets/jealousleopard/goodreadsbooks, download the dataset, and save it locally.\n",
    "FILE = '../books.csv' \n",
    "\n",
    "# 2. Set up the name of the collection to be created.\n",
    "COLLECTION_NAME = 'title_db'\n",
    "\n",
    "# 3. Set up the dimension of the embeddings.\n",
    "DIMENSION = 1536\n",
    "\n",
    "# 4. Set up the number of records to process.\n",
    "COUNT = 100\n",
    "\n",
    "# 5. Set up the connection parameters for your Zilliz Cloud cluster.\n",
    "URI = 'YOUR_CLUSTER_ENDPOINT'\n",
    "\n",
    "TOKEN = 'YOUR_CLUSTER_TOKEN'\n",
    "\n",
    "# 6. Set up the OpenAI engine and API key to use.\n",
    "OPENAI_ENGINE = 'text-embedding-ada-002'  # Which engine to use\n",
    "openai.api_key = 'YOUR_OPENAI_API_KEY'  # Use your own Open AI API Key here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with Zilliz Cloud\n",
    "\n",
    "The following snippet deals with Zilliz Cloud and setting up the cluster for this use case. Within Zilliz Cloud, we need to set up a collection and index it. For more information on how to set up and use Zilliz Cloud, refer to [this link](https://docs.zilliz.com/docs/quick-start-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status(code=0, message=)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to Zilliz Cloud and create a collection\n",
    "\n",
    "connections.connect(\n",
    "    alias='default',\n",
    "    # Public endpoint obtained from Zilliz Cloud\n",
    "    uri=URI,\n",
    "    token=TOKEN\n",
    ")\n",
    "\n",
    "if COLLECTION_NAME in utility.list_collections():\n",
    "    utility.drop_collection(COLLECTION_NAME)\n",
    "\n",
    "fields = [\n",
    "    FieldSchema(name='id', dtype=DataType.INT64, descrition='Ids', is_primary=True, auto_id=False),\n",
    "    FieldSchema(name='title', dtype=DataType.VARCHAR, description='Title texts', max_length=200),\n",
    "    FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, description='Embedding vectors', dim=DIMENSION)\n",
    "]\n",
    "\n",
    "schema = CollectionSchema(fields=fields, description='Title collection')\n",
    "\n",
    "collection = Collection(\n",
    "    name=COLLECTION_NAME,\n",
    "    schema=schema,\n",
    ")\n",
    "\n",
    "index_params = {\n",
    "    'metric_type': 'L2',\n",
    "    'index_type': 'AUTOINDEX',\n",
    "    'params': {'nlist': 1024}\n",
    "}\n",
    "\n",
    "collection.create_index(\n",
    "    field_name='embedding', \n",
    "    index_params=index_params\n",
    ")\n",
    "\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting up the collection, we can begin inserting our data, which involves three steps: reading the data, embedding the titles, and inserting into Zilliz Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted:  Forever (Firstborn  #5)\n",
      "Inserted:  A Kiss Remembered\n",
      "Inserted:  Blubberina (Scrambled Legs  #5)\n",
      "Inserted:  Nanny Ogg's Cookbook\n",
      "Inserted:  One Hundred Years of Solitude\n",
      "Inserted:  Key Lime Pie Murder (Hannah Swensen  #9)\n",
      "Inserted:  The Collected Stories of Philip K. Dick 3: Second Variety\n",
      "Inserted:  The Call of the Mall: How we shop\n",
      "Inserted:  The Iliad\n",
      "Inserted:  The Origin of Consciousness in the Breakdown of the Bicameral Mind\n",
      "Inserted:  The Philosophy of History\n",
      "Inserted:  City of Glass: The Graphic Novel\n",
      "Inserted:  Shadow of the Moon (Moon #5)\n",
      "Inserted:  A Circle of Quiet (Crosswicks Journals #1)\n",
      "Inserted:  Demonic Males: Apes and the Origins of Human Violence\n",
      "Inserted:  On Crimes and Punishments\n",
      "Inserted:  Anleitung zum Zickigsein\n",
      "Inserted:  Tell No One\n",
      "Inserted:  For Her Own Good: Two Centuries of the Experts' Advice to Women\n",
      "Inserted:  Up Country\n",
      "Inserted:  Europe and the People Without History\n",
      "Inserted:  Presidential Assassins (History Makers)\n",
      "Inserted:  Homebody\n",
      "Inserted:  The Canterbury Tales\n",
      "Inserted:  Counting Christmas\n",
      "Inserted:  Rejoice (Redemption  #4)\n",
      "Inserted:  The Complete Poems (Poetry Library)\n",
      "Inserted:  The Beach House (Beach House #1)\n",
      "Inserted:  The John Adams Reader: Eseential Writings on an American Composer\n",
      "Inserted:  Kill Your Boyfriend\n",
      "Inserted:  Maison Ikkoku  Volume 9 (Maison Ikkoku  #9)\n",
      "Inserted:  The Dark Side Of Genius: The Life Of Alfred Hitchcock\n",
      "Inserted:  At the Edge of the World (Crispin  #2)\n",
      "Inserted:  South Park and Philosophy: You Know  I Learned Something Today\n",
      "Inserted:  The Pure in Heart (Simon Serrailler  #2)\n",
      "Inserted:  The Gilded Web (Web  #1)\n",
      "Inserted:  A Clockwork Orange (Stage Play)\n",
      "Inserted:  The Gospel of Filth: A Bible of Decadence & Darkness\n",
      "Inserted:  The State of Mind Called Beautiful\n",
      "Inserted:  The Iliad/The Odyssey\n",
      "Inserted:  The Moon And Sixpence\n",
      "Inserted:  The Red Badge of Courage & The Veteran\n",
      "Inserted:  Utena: Revolutionary Girl 01\n",
      "Inserted:  Anna Karenina\n",
      "Inserted:  Desert Children\n",
      "Inserted:  Whirlpool\n",
      "Inserted:  No Heroes: A Memoir of Coming Home\n",
      "Inserted:  Invisible\n",
      "Inserted:  Ward No. 6 and Other Stories\n",
      "Inserted:  Corvette: Fifty Years\n",
      "Inserted:  Crescent and Star: Turkey Between Two Worlds\n",
      "Inserted:  A Separate Peace\n",
      "Inserted:  The Harry Bosch Novels  Volume 2: The Last Coyote / Trunk Music / Angels Flight (Harry Bosch  #4-6)\n",
      "Inserted:  The Seville Communion\n",
      "Inserted:  Peter Pan And Wendy\n",
      "Inserted:  Beyond the Post-Modern Mind: The Place of Meaning in a Global Civilization\n",
      "Inserted:  Fine Lines (One-Eyed Mack  #6)\n",
      "Inserted:  Spares\n",
      "Inserted:  Alvin Journeyman (Tales of Alvin Maker  #4)\n",
      "Inserted:  The Vampire Lestat (The Vampire Chronicles  #2)\n",
      "Inserted:  Persuasive Communication\n",
      "Inserted:  This Is Berlin: Reporting from Nazi Germany 1938-40\n",
      "Inserted:  And the Band Played On: Politics  People  and the AIDS Epidemic\n",
      "Inserted:  The Church and the Second Sex\n",
      "Inserted:  Seven Japanese Tales\n",
      "Inserted:  Creepers\n",
      "Inserted:  The White Wolf's Son: The Albino Underground (Elric & Oona Von Bek  #3)\n",
      "Inserted:  The Rocky Road to Romance (Elsie Hawkins #4)\n",
      "Inserted:  Cards on the Table (Hercule Poirot  #15)\n",
      "Inserted:  The Realm of Possibility\n",
      "Inserted:  Liars and Saints\n",
      "Inserted:  Eight Mindful Steps to Happiness: Walking the Buddha's Path\n",
      "Inserted:  The Last Jew\n",
      "Inserted:  The Stephen King Collection: Stories from Night Shift\n",
      "Inserted:  Earth  Air  Fire  Water (Tales from the Eternal Archives  #2)\n",
      "Inserted:  Political Philosophy: A Beginners' Guide for Students and Politicians\n",
      "Inserted:  The Age Of Shakespeare\n",
      "Inserted:  Search the Dark (Inspector Ian Rutledge  #3)\n",
      "Inserted:  Salvation to the Ends of the Earth: A Biblical Theology of Mission (New Studies in Biblical Theology (InterVarsity Press)  #11)\n",
      "Inserted:  Notebook of a Return to the Native Land\n",
      "Inserted:  Rebellion (The MacGregors  #0.1)\n",
      "Inserted:  Saving Fish from Drowning\n",
      "Inserted:  The Book of the Dragon\n",
      "Inserted:  The Eyre Affair (Thursday Next  #1)\n",
      "Inserted:  A Philosophical Enquiry into the Origin of our Ideas of the Sublime and Beautiful\n",
      "Inserted:  You Belong To Me\n",
      "Inserted:  Ein Koch fÃ¼r Mma Ramotswe (No. 1 Ladies' Detective Agency  #3)\n",
      "Inserted:  Talk Talk\n",
      "Inserted:  East and West: The Making of a Rift in the Church from Apostolic Times until the Council of Florence (History of the Christian Church)\n",
      "Inserted:  The Outsiders\n",
      "Inserted:  When the Emperor Was Divine\n",
      "Inserted:  How to Read Literature Like a Professor\n",
      "Inserted:  The Glory and the Dream: A Narrative History of America 1932-72\n",
      "Inserted:  Haunted (Women of the Otherworld  #5)\n",
      "Inserted:  The Two Towers (The Lord of the Rings  #2)\n",
      "Inserted:  Discovering God's Will\n",
      "Inserted:  Jasmine and Stars: Reading More Than Lolita in Tehran\n",
      "Inserted:  The Moon is a Harsh Mistress\n",
      "Inserted:  On Film (Thinking in Action)\n",
      "Inserted:  The Best American Classics\n"
     ]
    }
   ],
   "source": [
    "# Load the csv file and extract embeddings from the text\n",
    "\n",
    "def csv_load(file):\n",
    "    with open(file, newline='') as f:\n",
    "        reader=csv.reader(f, delimiter=',')\n",
    "        for row in reader:\n",
    "            yield row[1]\n",
    "\n",
    "def embed(text):\n",
    "    return openai.Embedding.create(\n",
    "        input=text, \n",
    "        engine=OPENAI_ENGINE)[\"data\"][0][\"embedding\"]\n",
    "\n",
    "# Insert each title and its embeddings\n",
    "\n",
    "for idx, text in enumerate(random.sample(sorted(csv_load(FILE)), k=COUNT)):\n",
    "    ins = {\n",
    "        'id': idx,\n",
    "        'title': (text[:198] + '..') if len(text) > 200 else text,\n",
    "        'embedding': embed(text)\n",
    "    }\n",
    "    collection.insert(data=ins)\n",
    "    time.sleep(3)\n",
    "    print('Inserted: ', ins['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search term:  self-improvement\n",
      "\n",
      "Search term:  landscape\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Search for similar titles\n",
    "def search(text):\n",
    "    res = collection.search(\n",
    "        data=[embed(text)],\n",
    "        anns_field='embedding',\n",
    "        param={\"metric_type\": \"L2\", \"params\": {\"nprobe\": 10}},\n",
    "        output_fields=['title'],\n",
    "        limit=5,\n",
    "    )\n",
    "\n",
    "    ret = []\n",
    "\n",
    "    for hits in res:\n",
    "        for hit in hits:\n",
    "            row = []\n",
    "            row.extend([hit['id'], hit['distance'], hit['entity']['title']])\n",
    "            ret.append(row)\n",
    "\n",
    "    return ret\n",
    "\n",
    "search_terms = [\n",
    "    'self-improvement',\n",
    "    'landscape',\n",
    "]\n",
    "\n",
    "for x in search_terms:\n",
    "    print('Search term: ', x)\n",
    "    for x in search(x):\n",
    "        print(x)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
