{"cells":[{"cell_type":"markdown","metadata":{"id":"dC5Gu87ItwX-"},"source":["# Use BulkWriter for Data Import (2): Use RemoteBulkWriter\n","\n","This notebook helps you learn how to use PyMilvus' RemoteBulkWriter to prepare your dataset ready to import to Zilliz Cloud.\n","\n","## Before you start\n","Ensure that:\n","\n","- Install the dependencies, including PyMilvus and MinIO Python Client.\n","- Create an output folder for the storage of the BulkWriter output."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8300,"status":"ok","timestamp":1695030956250,"user":{"displayName":"Anthony Tu","userId":"00804977476441304836"},"user_tz":-480},"id":"LodB5U0PtnUS","outputId":"48bb9463-d585-49e2-cad7-c472328e7440"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pymilvus in ./lib/python3.11/site-packages (2.3.2)\n","Requirement already satisfied: minio in ./lib/python3.11/site-packages (7.1.16)\n","Requirement already satisfied: grpcio<=1.58.0,>=1.49.1 in ./lib/python3.11/site-packages (from pymilvus) (1.56.0)\n","Requirement already satisfied: protobuf>=3.20.0 in ./lib/python3.11/site-packages (from pymilvus) (4.24.3)\n","Requirement already satisfied: environs<=9.5.0 in ./lib/python3.11/site-packages (from pymilvus) (9.5.0)\n","Requirement already satisfied: ujson>=2.0.0 in ./lib/python3.11/site-packages (from pymilvus) (5.8.0)\n","Requirement already satisfied: pandas>=1.2.4 in ./lib/python3.11/site-packages (from pymilvus) (2.1.0)\n","Requirement already satisfied: requests in ./lib/python3.11/site-packages (from pymilvus) (2.31.0)\n","Requirement already satisfied: certifi in ./lib/python3.11/site-packages (from minio) (2023.7.22)\n","Requirement already satisfied: urllib3 in ./lib/python3.11/site-packages (from minio) (1.26.18)\n","Requirement already satisfied: marshmallow>=3.0.0 in ./lib/python3.11/site-packages (from environs<=9.5.0->pymilvus) (3.20.1)\n","Requirement already satisfied: python-dotenv in ./lib/python3.11/site-packages (from environs<=9.5.0->pymilvus) (1.0.0)\n","Requirement already satisfied: numpy>=1.23.2 in ./lib/python3.11/site-packages (from pandas>=1.2.4->pymilvus) (1.25.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in ./lib/python3.11/site-packages (from pandas>=1.2.4->pymilvus) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in ./lib/python3.11/site-packages (from pandas>=1.2.4->pymilvus) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in ./lib/python3.11/site-packages (from pandas>=1.2.4->pymilvus) (2023.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in ./lib/python3.11/site-packages (from requests->pymilvus) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in ./lib/python3.11/site-packages (from requests->pymilvus) (3.4)\n","Requirement already satisfied: packaging>=17.0 in ./lib/python3.11/site-packages (from marshmallow>=3.0.0->environs<=9.5.0->pymilvus) (23.1)\n","Requirement already satisfied: six>=1.5 in ./lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus) (1.16.0)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install pymilvus minio"]},{"cell_type":"markdown","metadata":{"id":"hUmUey10t-zO"},"source":["## Import the dependencies\n","\n","In this part, you need to import the dependencies required to run this notebook, including PyMilvus for the operations with Zilliz Cloud clusters, MinIO for the operations with your object storage bucket, Pandas for data processing of your dataset, and some standard libraries."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"ygL11MBquP8U"},"outputs":[],"source":["from pathlib import Path\n","import os, json\n","\n","import pandas as pd\n","from minio import Minio\n","\n","from pymilvus import (\n","    FieldSchema, CollectionSchema, DataType,\n","    RemoteBulkWriter,\n",")\n","\n","\n","ACCESS_KEY = \"YOUR_OBJECT_STORAGE_ACCESS_KEY\"\n","SECRET_KEY = \"YOUR_OBJECT_STORAGE_SECRET_KEY\"\n","BUCKET_NAME = \"YOUR_OBJECT_STORAGE_BUCKET_NAME\"\n","REMOTE_PATH = \"DATA_FILES_PATH_IN_BLOCK_STORAGE\"\n","DATASET_PATH = \"../New_Medium_Data.csv\"\n"]},{"cell_type":"markdown","metadata":{"id":"FdPlN1iCusFt"},"source":["## Determine collection schema\n","\n","You need to work out a collection schema out of your dataset. This demo uses [this example dataset](https://drive.google.com/file/d/12RkoDPAlk-sclXdjeXT6DMFVsQr4612w/view?usp=drive_link), and collection will be as the following."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"VtA0M7fhusvo"},"outputs":[],"source":["fields = [\n","    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True),\n","    FieldSchema(name=\"title\", dtype=DataType.VARCHAR, max_length=512),\n","    FieldSchema(name=\"vector\", dtype=DataType.FLOAT_VECTOR, dim=768),\n","    FieldSchema(name=\"link\", dtype=DataType.VARCHAR, max_length=512),\n","    FieldSchema(name=\"reading_time\", dtype=DataType.INT64),\n","    FieldSchema(name=\"publication\", dtype=DataType.VARCHAR, max_length=512),\n","    FieldSchema(name=\"claps\", dtype=DataType.INT64),\n","    FieldSchema(name=\"responses\", dtype=DataType.INT64)\n","]\n","\n","schema = CollectionSchema(fields)"]},{"cell_type":"markdown","metadata":{"id":"tFOl0GdSuz2E"},"source":["## Rewrite your dataset\n","\n","Once the schema is ready, you can rewrite your data into a format that Zilliz Cloud understands in an object storage bucket.\n","\n","To do so, you need to:\n","\n","- Create a `ConnectParam` for the connection to your object storage bucket.\n","- Create a `RemoteBulkWriter` with the following parameters:\n","  - `schema`: Schema of the target collection.\n","  - `remote_path`: Path to the folder to hold the output file in the specified bucket .\n","  - `segment_size`: Maximum size of a generated file of set of files. If the size of your dataset exceeds the specified value, multiple files or sets of files are to be generated.\n","  - `connect_param`: Connection parameters for the connection to your object storage."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15262,"status":"ok","timestamp":1695031925824,"user":{"displayName":"Anthony Tu","userId":"00804977476441304836"},"user_tz":-480},"id":"OCOH5hpOvE9n","outputId":"457af52d-138f-47bc-adc0-e651faa4f418"},"outputs":[{"name":"stdout","output_type":"stream","text":["/numpy-files/f6edff70-b5ca-467d-b5ee-981a98979743\n"]}],"source":["# Extract the ID from the share link of the dataset file.\n","# For a file at https://drive.google.com/file/d/12RkoDPAlk-sclXdjeXT6DMFVsQr4612w/view?usp=drive_link, the ID should be 12RkoDPAlk-sclXdjeXT6DMFVsQr4612w.\n","# Concatenate the file ID to the end of the url as follows:\n","\n","url = Path(DATASET_PATH)\n","dataset = pd.read_csv(url)\n","\n","connect_param = RemoteBulkWriter.ConnectParam(\n","    endpoint=\"storage.googleapis.com\", # use 's3.amazonaws.com' for GCS\n","    access_key=ACCESS_KEY,\n","    secret_key=SECRET_KEY,\n","    bucket_name=BUCKET_NAME,\n","    secure=True\n",")\n","\n","remote_writer = RemoteBulkWriter(\n","    schema=schema,\n","    remote_path=REMOTE_PATH,\n","    segment_size=50*1024*1024,\n","    connect_param=connect_param,\n",")\n","\n","for i in range(0, len(dataset)):\n","  row = dataset.iloc[i].to_dict()\n","  row[\"vector\"] = json.loads(row[\"vector\"])\n","  remote_writer.append_row(row)\n","\n","remote_writer.commit()\n","\n","print(remote_writer.data_path)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1835,"status":"ok","timestamp":1695032808248,"user":{"displayName":"Anthony Tu","userId":"00804977476441304836"},"user_tz":-480},"id":"h1kqOFPxxyfP","outputId":"4ef589a0-ea0b-4998-80f2-ec2f0e68f90a"},"outputs":[{"name":"stdout","output_type":"stream","text":["['numpy-files/f6edff70-b5ca-467d-b5ee-981a98979743/1/claps.npy', 'numpy-files/f6edff70-b5ca-467d-b5ee-981a98979743/1/id.npy', 'numpy-files/f6edff70-b5ca-467d-b5ee-981a98979743/1/link.npy', 'numpy-files/f6edff70-b5ca-467d-b5ee-981a98979743/1/publication.npy', 'numpy-files/f6edff70-b5ca-467d-b5ee-981a98979743/1/reading_time.npy', 'numpy-files/f6edff70-b5ca-467d-b5ee-981a98979743/1/responses.npy', 'numpy-files/f6edff70-b5ca-467d-b5ee-981a98979743/1/title.npy', 'numpy-files/f6edff70-b5ca-467d-b5ee-981a98979743/1/vector.npy']\n"]}],"source":["# To check the files in the remote folder\n","\n","client = Minio(\n","    endpoint=\"storage.googleapis.com\", # use 's3.amazonaws.com' for AWS\n","    access_key=ACCESS_KEY,\n","    secret_key=SECRET_KEY,\n","    secure=True)\n","\n","objects = client.list_objects(\n","    bucket_name=BUCKET_NAME,\n","    prefix=str(remote_writer.data_path)[1:],\n","    recursive=True\n",")\n","\n","print([obj.object_name for obj in objects])"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMelATROJpKESzooT//whL8","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
